{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMENLsFZ4BW8JG8UZdVGJZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaitanyaj2121/Comp-Multiservises-mini-project/blob/main/ca1_deeplearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0BwsI1cmJAXj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1: Build a Simple Neural Network\n",
        "Implement a single-layer neural network using NumPy.\n",
        "Train it on a small dataset (e.g., XOR function).\n"
      ],
      "metadata": {
        "id": "5xNb97I8JH6B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the XOR dataset\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])  # Inputs\n",
        "y = np.array([[0], [1], [1], [0]])              # Outputs\n",
        "\n",
        "# Define parameters\n",
        "input_size = 2\n",
        "output_size = 1\n",
        "learning_rate = 0.1\n",
        "iterations = 10000\n",
        "\n",
        "# Initialize weights and bias\n",
        "weights = np.random.uniform(-1, 1, (input_size, output_size))\n",
        "bias = np.random.uniform(-1, 1, (1, output_size))\n",
        "\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training the network\n",
        "for epoch in range(iterations):\n",
        "    # Forward propagation\n",
        "    weighted_sum = np.dot(X, weights) + bias\n",
        "    predictions = sigmoid(weighted_sum)\n",
        "\n",
        "    # Calculate error\n",
        "    error = y - predictions\n",
        "\n",
        "    # Backpropagation\n",
        "    d_pred = error * sigmoid_derivative(predictions)\n",
        "\n",
        "    # Update weights and bias\n",
        "    weights += np.dot(X.T, d_pred) * learning_rate\n",
        "    bias += np.sum(d_pred, axis=0, keepdims=True) * learning_rate\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f'Epoch {epoch}, Loss: {loss}')\n",
        "\n",
        "# Final predictions\n",
        "print(\"\\nFinal Predictions:\")\n",
        "print(np.round(predictions))\n"
      ],
      "metadata": {
        "id": "qItMjom2JNXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2: Gradient Descent Visualization\n",
        "Implement gradient descent for a simple function.\n",
        "Plot the loss function over iterations to show convergence.\n",
        "\n"
      ],
      "metadata": {
        "id": "TrhshNXKJlvk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the simple function: f(x) = x^2\n",
        "def function(x):\n",
        "    return x ** 2\n",
        "\n",
        "# Define the derivative of the function: f'(x) = 2x\n",
        "def gradient(x):\n",
        "    return 2 * x\n",
        "\n",
        "# Parameters\n",
        "learning_rate = 0.1\n",
        "iterations = 50\n",
        "initial_x = 5  # Starting point\n",
        "\n",
        "# Lists to store values for plotting\n",
        "x_values = []\n",
        "y_values = []\n",
        "\n",
        "# Gradient Descent Loop\n",
        "x = initial_x\n",
        "for i in range(iterations):\n",
        "    x_values.append(x)\n",
        "    y_values.append(function(x))\n",
        "\n",
        "    # Gradient descent update\n",
        "    x = x - learning_rate * gradient(x)\n",
        "\n",
        "# Plot the loss function over iterations\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(range(iterations), y_values, 'b-', marker='o')\n",
        "plt.title('Gradient Descent Convergence')\n",
        "plt.xlabel('Iterations')\n",
        "plt.ylabel('Loss (f(x) = x^2)')\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "0jJ0Wn09JYS7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3: Image Classification Using CNN\n",
        "Train a CNN model on a small dataset (e.g., CIFAR-10 or MNIST).\n",
        "Compare performance with and without data augmentation.\n",
        "\n"
      ],
      "metadata": {
        "id": "pBmmGZDgJ0vU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Normalize the data\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape the data to fit CNN input\n",
        "x_train = x_train.reshape(-1, 28, 28, 1)\n",
        "x_test = x_test.reshape(-1, 28, 28, 1)\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Define CNN model\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Conv2D(64, (3, 3), activation='relu'),\n",
        "        MaxPooling2D((2, 2)),\n",
        "        Flatten(),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(10, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Model without Data Augmentation\n",
        "model_no_aug = create_model()\n",
        "history_no_aug = model_no_aug.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test))\n",
        "\n",
        "# Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(x_train)\n",
        "\n",
        "# Model with Data Augmentation\n",
        "model_with_aug = create_model()\n",
        "history_with_aug = model_with_aug.fit(datagen.flow(x_train, y_train, batch_size=64),\n",
        "                                      epochs=10,\n",
        "                                      validation_data=(x_test, y_test))\n",
        "\n",
        "# Compare Performance\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot accuracy\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history_no_aug.history['accuracy'], label='No Augmentation')\n",
        "plt.plot(history_with_aug.history['accuracy'], label='With Augmentation')\n",
        "plt.title('Training Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "# Plot validation accuracy\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history_no_aug.history['val_accuracy'], label='No Augmentation')\n",
        "plt.plot(history_with_aug.history['val_accuracy'], label='With Augmentation')\n",
        "plt.title('Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kcwdogoCJNjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models, applications, optimizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "import cv2\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Configuration\n",
        "CONFIG = {\n",
        "    'dataset': 'custom',     # Options: 'coco', 'voc', 'custom'\n",
        "    'model_type': 'ssd',     # Options: 'yolo', 'ssd', 'faster_rcnn', 'custom'\n",
        "    'image_size': (300, 300),\n",
        "    'batch_size': 16,\n",
        "    'epochs': 50,\n",
        "    'learning_rate': 0.001,\n",
        "    'data_augmentation': True,\n",
        "    'pretrained': True,\n",
        "    'num_classes': 3,        # Excluding background class\n",
        "}\n",
        "\n",
        "# 1. Dataset Preprocessing\n",
        "def preprocess_dataset(dataset_path, image_size):\n",
        "    \"\"\"\n",
        "    Preprocess the dataset for object detection tasks\n",
        "\n",
        "    Args:\n",
        "        dataset_path: Path to the dataset\n",
        "        image_size: Target image size for the model\n",
        "\n",
        "    Returns:\n",
        "        Processed images and annotations\n",
        "    \"\"\"\n",
        "    # For demonstration purposes, let's assume we have a simple dataset structure\n",
        "    # with images and corresponding annotation files\n",
        "    images = []\n",
        "    annotations = []\n",
        "\n",
        "    # In a real implementation, you would load your dataset from files\n",
        "    # This is just a placeholder for the actual data loading code\n",
        "    print(f\"Loading dataset from {dataset_path}...\")\n",
        "\n",
        "    # Simulating dataset loading\n",
        "    if CONFIG['dataset'] == 'custom':\n",
        "        # Example for a custom dataset with 3 classes (e.g., person, car, dog)\n",
        "        # In a real scenario, you would parse annotation files (XML, JSON, etc.)\n",
        "        print(\"Creating synthetic data for demonstration...\")\n",
        "\n",
        "        # Create synthetic data for demonstration\n",
        "        num_samples = 100\n",
        "        X = np.random.randint(0, 255, (num_samples, *image_size, 3), dtype=np.uint8)\n",
        "\n",
        "        # Generate synthetic annotations (bounding boxes)\n",
        "        y = []\n",
        "        for _ in range(num_samples):\n",
        "            num_objects = np.random.randint(1, 4)\n",
        "            sample_boxes = []\n",
        "\n",
        "            for _ in range(num_objects):\n",
        "                # Format: [class_id, x_min, y_min, x_max, y_max, confidence]\n",
        "                class_id = np.random.randint(0, CONFIG['num_classes'])\n",
        "                width = np.random.randint(50, 150)\n",
        "                height = np.random.randint(50, 150)\n",
        "                x_min = np.random.randint(0, image_size[0] - width)\n",
        "                y_min = np.random.randint(0, image_size[1] - height)\n",
        "\n",
        "                box = [\n",
        "                    class_id,\n",
        "                    x_min / image_size[0],\n",
        "                    y_min / image_size[1],\n",
        "                    (x_min + width) / image_size[0],\n",
        "                    (y_min + height) / image_size[1],\n",
        "                    1.0  # Confidence\n",
        "                ]\n",
        "                sample_boxes.append(box)\n",
        "\n",
        "            y.append(np.array(sample_boxes))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    elif CONFIG['dataset'] in ['coco', 'voc']:\n",
        "        print(f\"In a real implementation, you would load the {CONFIG['dataset']} dataset here.\")\n",
        "        # Placeholder for loading COCO or VOC datasets\n",
        "        # You would use libraries like pycocotools for COCO\n",
        "        # or parse XML annotations for VOC\n",
        "\n",
        "        # For demonstration, creating synthetic data\n",
        "        num_samples = 100\n",
        "        X = np.random.randint(0, 255, (num_samples, *image_size, 3), dtype=np.uint8)\n",
        "\n",
        "        # Generate synthetic annotations\n",
        "        y = []\n",
        "        for _ in range(num_samples):\n",
        "            num_objects = np.random.randint(1, 4)\n",
        "            sample_boxes = []\n",
        "\n",
        "            for _ in range(num_objects):\n",
        "                class_id = np.random.randint(0, CONFIG['num_classes'])\n",
        "                width = np.random.randint(50, 150)\n",
        "                height = np.random.randint(50, 150)\n",
        "                x_min = np.random.randint(0, image_size[0] - width)\n",
        "                y_min = np.random.randint(0, image_size[1] - height)\n",
        "\n",
        "                box = [\n",
        "                    class_id,\n",
        "                    x_min / image_size[0],\n",
        "                    y_min / image_size[1],\n",
        "                    (x_min + width) / image_size[0],\n",
        "                    (y_min + height) / image_size[1],\n",
        "                    1.0\n",
        "                ]\n",
        "                sample_boxes.append(box)\n",
        "\n",
        "            y.append(np.array(sample_boxes))\n",
        "\n",
        "        return X, y\n",
        "\n",
        "    print(\"Dataset loaded and preprocessed\")\n",
        "    return images, annotations\n",
        "\n",
        "# 2. Build or Load Model\n",
        "def get_model(model_type, input_shape, num_classes, pretrained=True):\n",
        "    \"\"\"\n",
        "    Build or load a pre-trained object detection model\n",
        "\n",
        "    Args:\n",
        "        model_type: Type of model ('yolo', 'ssd', 'faster_rcnn', 'custom')\n",
        "        input_shape: Input image shape\n",
        "        num_classes: Number of object classes to detect\n",
        "        pretrained: Whether to use pre-trained weights\n",
        "\n",
        "    Returns:\n",
        "        Object detection model\n",
        "    \"\"\"\n",
        "    if model_type == 'custom':\n",
        "        # Build a custom CNN for object detection\n",
        "        model = models.Sequential([\n",
        "            layers.Input(shape=input_shape),\n",
        "\n",
        "            # Feature extraction layers\n",
        "            layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "            # Detection layers - simplified for demonstration\n",
        "            layers.Conv2D(256, (3, 3), activation='relu', padding='same'),\n",
        "            layers.Conv2D((num_classes + 5) * 5, (1, 1), padding='same')  # 5 anchor boxes, each with (x,y,w,h,conf,classes)\n",
        "        ])\n",
        "\n",
        "        print(\"Custom CNN model created\")\n",
        "        return model\n",
        "\n",
        "    elif model_type == 'ssd':\n",
        "        # In a real implementation, you would use a proper SSD implementation\n",
        "        # This is a simplified placeholder that demonstrates the concept\n",
        "\n",
        "        # Use MobileNetV2 as the base model\n",
        "        base_model = applications.MobileNetV2(\n",
        "            input_shape=(*input_shape, 3),\n",
        "            include_top=False,\n",
        "            weights='imagenet' if pretrained else None\n",
        "        )\n",
        "\n",
        "        # Freeze the base model layers\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Add SSD detection heads (simplified for demonstration)\n",
        "        inputs = layers.Input(shape=(*input_shape, 3))\n",
        "        x = preprocess_input(inputs)\n",
        "        x = base_model(x)\n",
        "\n",
        "        # Detection head\n",
        "        # In a real SSD implementation, you would add multiple detection heads\n",
        "        # on feature maps of different scales\n",
        "        x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "        output = layers.Conv2D((num_classes + 5) * 6, (3, 3), padding='same')(x)\n",
        "\n",
        "        model = models.Model(inputs=inputs, outputs=output)\n",
        "        print(\"SSD model (simplified) with MobileNetV2 backbone created\")\n",
        "        return model\n",
        "\n",
        "    elif model_type == 'yolo':\n",
        "        # In a real implementation, you would use a proper YOLO implementation\n",
        "        print(\"In a real implementation, you would load or implement YOLO here\")\n",
        "\n",
        "        # Placeholder for demonstration\n",
        "        base_model = applications.MobileNetV2(\n",
        "            input_shape=(*input_shape, 3),\n",
        "            include_top=False,\n",
        "            weights='imagenet' if pretrained else None\n",
        "        )\n",
        "\n",
        "        # Freeze the base model layers\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Add YOLO-style detection head (simplified)\n",
        "        inputs = layers.Input(shape=(*input_shape, 3))\n",
        "        x = preprocess_input(inputs)\n",
        "        x = base_model(x)\n",
        "\n",
        "        # Detection head\n",
        "        x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "        output = layers.Conv2D((num_classes + 5) * 3, (1, 1), padding='same')(x)  # 3 anchor boxes\n",
        "\n",
        "        model = models.Model(inputs=inputs, outputs=output)\n",
        "        print(\"YOLO-style model (simplified) with MobileNetV2 backbone created\")\n",
        "        return model\n",
        "\n",
        "    elif model_type == 'faster_rcnn':\n",
        "        # In a real implementation, you would use a proper Faster R-CNN implementation\n",
        "        print(\"In a real implementation, you would load or implement Faster R-CNN here\")\n",
        "\n",
        "        # Placeholder for demonstration\n",
        "        print(\"Faster R-CNN is more complex and requires region proposal network\")\n",
        "        print(\"Using a simplified placeholder model for demonstration\")\n",
        "\n",
        "        # Use ResNet50 as the backbone\n",
        "        base_model = applications.ResNet50(\n",
        "            input_shape=(*input_shape, 3),\n",
        "            include_top=False,\n",
        "            weights='imagenet' if pretrained else None\n",
        "        )\n",
        "\n",
        "        # Freeze the base model layers\n",
        "        base_model.trainable = False\n",
        "\n",
        "        # Simplified detection head\n",
        "        inputs = layers.Input(shape=(*input_shape, 3))\n",
        "        x = preprocess_input(inputs)\n",
        "        x = base_model(x)\n",
        "\n",
        "        # RPN and detection head (simplified)\n",
        "        x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
        "        output = layers.Conv2D((num_classes + 5) * 9, (1, 1), padding='same')(x)  # 9 anchor boxes\n",
        "\n",
        "        model = models.Model(inputs=inputs, outputs=output)\n",
        "        print(\"Faster R-CNN-style model (simplified) with ResNet50 backbone created\")\n",
        "        return model\n",
        "\n",
        "# 3. Data Augmentation\n",
        "def create_data_generators(X, y, image_size, batch_size, augmentation=True):\n",
        "    \"\"\"\n",
        "    Create data generators for training and validation with optional augmentation\n",
        "\n",
        "    Args:\n",
        "        X: Images\n",
        "        y: Annotations\n",
        "        image_size: Target image size\n",
        "        batch_size: Batch size\n",
        "        augmentation: Whether to apply data augmentation\n",
        "\n",
        "    Returns:\n",
        "        Training and validation data generators\n",
        "    \"\"\"\n",
        "    # Split the data into training and validation sets\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # In a real implementation, you would create a custom data generator\n",
        "    # that applies augmentation while preserving bounding box coordinates\n",
        "\n",
        "    print(f\"Training set: {len(X_train)} samples\")\n",
        "    print(f\"Validation set: {len(X_val)} samples\")\n",
        "\n",
        "    if augmentation:\n",
        "        print(\"Applying data augmentation techniques:\")\n",
        "        print(\"- Random horizontal flip\")\n",
        "        print(\"- Random brightness and contrast adjustment\")\n",
        "        print(\"- Random translation\")\n",
        "        # Note: In a real implementation, you would ensure bounding boxes are transformed accordingly\n",
        "\n",
        "    # Return the training and validation data\n",
        "    # In a real implementation, this would be actual generators\n",
        "    return (X_train, y_train), (X_val, y_val)\n",
        "\n",
        "# 4. Custom Loss Function\n",
        "def detection_loss(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Simplified object detection loss function\n",
        "\n",
        "    In a real implementation, this would be a proper object detection loss\n",
        "    like SSD loss, YOLO loss, or Faster R-CNN loss\n",
        "\n",
        "    Args:\n",
        "        y_true: Ground truth annotations\n",
        "        y_pred: Model predictions\n",
        "\n",
        "    Returns:\n",
        "        Loss value\n",
        "    \"\"\"\n",
        "    # This is a placeholder for demonstration\n",
        "    # Real object detection losses are much more complex\n",
        "    print(\"In a real implementation, you would use a proper object detection loss\")\n",
        "\n",
        "    # Placeholder loss function\n",
        "    # Classification loss (simplified)\n",
        "    class_loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "    # Regression loss for bounding boxes (simplified)\n",
        "    box_loss = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    # Combination of losses\n",
        "    # total_loss = class_loss + box_loss\n",
        "    # In practice, you would extract class predictions and box predictions\n",
        "    # from y_pred and apply the appropriate loss to each\n",
        "\n",
        "    return y_pred  # Placeholder\n",
        "\n",
        "# 5. Training Function\n",
        "def train_model(model, train_data, val_data, epochs, learning_rate):\n",
        "    \"\"\"\n",
        "    Train the object detection model\n",
        "\n",
        "    Args:\n",
        "        model: Object detection model\n",
        "        train_data: Training data\n",
        "        val_data: Validation data\n",
        "        epochs: Number of training epochs\n",
        "        learning_rate: Learning rate\n",
        "\n",
        "    Returns:\n",
        "        Trained model and training history\n",
        "    \"\"\"\n",
        "    print(f\"Training model for {epochs} epochs with learning rate {learning_rate}\")\n",
        "\n",
        "    # Set up optimizer\n",
        "    optimizer = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Compile the model\n",
        "    # Note: In a real implementation, you would use a proper object detection loss\n",
        "    model.compile(\n",
        "        optimizer=optimizer,\n",
        "        loss='mse',  # Placeholder - would use actual detection loss in real implementation\n",
        "        metrics=['accuracy']  # Not directly applicable to object detection, but used for demo\n",
        "    )\n",
        "\n",
        "    # Set up callbacks\n",
        "    callbacks = [\n",
        "        ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss'),\n",
        "        EarlyStopping(patience=10, monitor='val_loss'),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=5, monitor='val_loss')\n",
        "    ]\n",
        "\n",
        "    # In a real implementation, you would feed your data through a proper generator\n",
        "    # This is a simplified placeholder for demonstration\n",
        "    print(\"In a real implementation, you would train with actual data\")\n",
        "    print(\"Simulating training process...\")\n",
        "\n",
        "    # Simulated training history\n",
        "    history = {\n",
        "        'loss': [np.random.random() * 0.5 for _ in range(min(epochs, 10))],\n",
        "        'val_loss': [np.random.random() * 0.6 for _ in range(min(epochs, 10))],\n",
        "        'accuracy': [0.5 + np.random.random() * 0.4 for _ in range(min(epochs, 10))],\n",
        "        'val_accuracy': [0.5 + np.random.random() * 0.3 for _ in range(min(epochs, 10))]\n",
        "    }\n",
        "\n",
        "    # In a real implementation:\n",
        "    # history = model.fit(\n",
        "    #     train_generator,\n",
        "    #     validation_data=val_generator,\n",
        "    #     epochs=epochs,\n",
        "    #     callbacks=callbacks\n",
        "    # )\n",
        "\n",
        "    print(\"Model training completed (simulated)\")\n",
        "    return model, history\n",
        "\n",
        "# 6. Evaluation Function\n",
        "def evaluate_model(model, test_data):\n",
        "    \"\"\"\n",
        "    Evaluate the model performance\n",
        "\n",
        "    Args:\n",
        "        model: Trained object detection model\n",
        "        test_data: Test data\n",
        "\n",
        "    Returns:\n",
        "        Evaluation metrics\n",
        "    \"\"\"\n",
        "    print(\"Evaluating model performance...\")\n",
        "\n",
        "    # In a real implementation, you would:\n",
        "    # 1. Run inference on test data\n",
        "    # 2. Calculate mAP (mean Average Precision) and other metrics\n",
        "\n",
        "    print(\"In a real implementation, you would calculate mAP\")\n",
        "    print(\"Simulating evaluation process...\")\n",
        "\n",
        "    # Simulated mAP values\n",
        "    mAP = 0.65 + np.random.random() * 0.2\n",
        "    class_APs = {\n",
        "        'class_0': 0.7 + np.random.random() * 0.2,\n",
        "        'class_1': 0.6 + np.random.random() * 0.2,\n",
        "        'class_2': 0.5 + np.random.random() * 0.3\n",
        "    }\n",
        "\n",
        "    print(f\"Simulated mAP: {mAP:.4f}\")\n",
        "    for class_name, ap in class_APs.items():\n",
        "        print(f\"AP for {class_name}: {ap:.4f}\")\n",
        "\n",
        "    return {'mAP': mAP, 'class_APs': class_APs}\n",
        "\n",
        "# 7. Inference Function\n",
        "def perform_inference(model, image, image_size, conf_threshold=0.5):\n",
        "    \"\"\"\n",
        "    Perform object detection on a single image\n",
        "\n",
        "    Args:\n",
        "        model: Trained object detection model\n",
        "        image: Input image\n",
        "        image_size: Target image size\n",
        "        conf_threshold: Confidence threshold for detections\n",
        "\n",
        "    Returns:\n",
        "        Detected objects (class, box coordinates, confidence)\n",
        "    \"\"\"\n",
        "    # Preprocess the image\n",
        "    img = cv2.resize(image, image_size)\n",
        "    img = np.expand_dims(img, axis=0)  # Add batch dimension\n",
        "\n",
        "    # Perform inference\n",
        "    print(\"In a real implementation, you would run the model on the input image\")\n",
        "    print(\"Simulating inference process...\")\n",
        "\n",
        "    # Simulated detections\n",
        "    # Format: [class_id, x_min, y_min, x_max, y_max, confidence]\n",
        "    num_detections = np.random.randint(1, 5)\n",
        "    detections = []\n",
        "\n",
        "    for _ in range(num_detections):\n",
        "        class_id = np.random.randint(0, CONFIG['num_classes'])\n",
        "        conf = 0.5 + np.random.random() * 0.5\n",
        "\n",
        "        if conf >= conf_threshold:\n",
        "            width = np.random.randint(50, 150)\n",
        "            height = np.random.randint(50, 150)\n",
        "            x_min = np.random.randint(0, image_size[0] - width)\n",
        "            y_min = np.random.randint(0, image_size[1] - height)\n",
        "\n",
        "            detection = [\n",
        "                class_id,\n",
        "                x_min / image_size[0],\n",
        "                y_min / image_size[1],\n",
        "                (x_min + width) / image_size[0],\n",
        "                (y_min + height) / image_size[1],\n",
        "                conf\n",
        "            ]\n",
        "            detections.append(detection)\n",
        "\n",
        "    return np.array(detections)\n",
        "\n",
        "# 8. Visualization Function\n",
        "def visualize_detections(image, detections, class_names, image_size):\n",
        "    \"\"\"\n",
        "    Visualize detected objects on the image\n",
        "\n",
        "    Args:\n",
        "        image: Input image\n",
        "        detections: Detected objects\n",
        "        class_names: Names of the object classes\n",
        "        image_size: Image size\n",
        "\n",
        "    Returns:\n",
        "        Image with drawn bounding boxes\n",
        "    \"\"\"\n",
        "    # Resize image if needed\n",
        "    if image.shape[:2] != image_size:\n",
        "        image = cv2.resize(image, image_size)\n",
        "\n",
        "    # Create a copy of the image for drawing\n",
        "    img = image.copy()\n",
        "\n",
        "    # Define colors for different classes\n",
        "    colors = [\n",
        "        (255, 0, 0),    # Red\n",
        "        (0, 255, 0),    # Green\n",
        "        (0, 0, 255),    # Blue\n",
        "        (255, 255, 0),  # Yellow\n",
        "        (255, 0, 255),  # Magenta\n",
        "        (0, 255, 255),  # Cyan\n",
        "    ]\n",
        "\n",
        "    # Draw each detection\n",
        "    for det in detections:\n",
        "        class_id, x_min, y_min, x_max, y_max, conf = det\n",
        "\n",
        "        # Convert normalized coordinates to pixel coordinates\n",
        "        x_min = int(x_min * image_size[0])\n",
        "        y_min = int(y_min * image_size[1])\n",
        "        x_max = int(x_max * image_size[0])\n",
        "        y_max = int(y_max * image_size[1])\n",
        "\n",
        "        # Get color for this class\n",
        "        color = colors[int(class_id) % len(colors)]\n",
        "\n",
        "        # Draw bounding box\n",
        "        cv2.rectangle(img, (x_min, y_min), (x_max, y_max), color, 2)\n",
        "\n",
        "        # Draw label\n",
        "        class_name = class_names[int(class_id)]\n",
        "        label = f\"{class_name}: {conf:.2f}\"\n",
        "        cv2.putText(img, label, (x_min, y_min - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    return img\n",
        "\n",
        "# 9. Main Function\n",
        "def main():\n",
        "    \"\"\"\n",
        "    Main function to run the object detection pipeline\n",
        "    \"\"\"\n",
        "    print(\"Object Detection using CNN\")\n",
        "    print(f\"Configuration: {CONFIG}\")\n",
        "\n",
        "    # Step 1: Dataset Preprocessing\n",
        "    print(\"\\n1. Dataset Preprocessing\")\n",
        "    dataset_path = \"./data\"  # Placeholder path\n",
        "    images, annotations = preprocess_dataset(dataset_path, CONFIG['image_size'])\n",
        "\n",
        "    # Step 2: Data Augmentation\n",
        "    print(\"\\n2. Data Augmentation\")\n",
        "    train_data, val_data = create_data_generators(\n",
        "        images, annotations, CONFIG['image_size'], CONFIG['batch_size'],\n",
        "        augmentation=CONFIG['data_augmentation']\n",
        "    )\n",
        "\n",
        "    # Step 3: Model Implementation\n",
        "    print(\"\\n3. Model Implementation\")\n",
        "    model = get_model(\n",
        "        CONFIG['model_type'],\n",
        "        CONFIG['image_size'],\n",
        "        CONFIG['num_classes'],\n",
        "        pretrained=CONFIG['pretrained']\n",
        "    )\n",
        "\n",
        "    # Print model summary\n",
        "    print(\"\\nModel Summary:\")\n",
        "    model.summary(line_length=80)\n",
        "\n",
        "    # Step 4: Training\n",
        "    print(\"\\n4. Training and Evaluation\")\n",
        "    trained_model, history = train_model(\n",
        "        model, train_data, val_data, CONFIG['epochs'], CONFIG['learning_rate']\n",
        "    )\n",
        "\n",
        "    # Step 5: Evaluation\n",
        "    print(\"\\n5. Model Evaluation\")\n",
        "    metrics = evaluate_model(trained_model, val_data)\n",
        "\n",
        "    # Step 6: Inference on Test Images\n",
        "    print(\"\\n6. Inference on Test Images\")\n",
        "    # Create a synthetic test image\n",
        "    test_image = np.random.randint(0, 255, (*CONFIG['image_size'], 3), dtype=np.uint8)\n",
        "\n",
        "    # Define class names\n",
        "    class_names = [f\"Class_{i}\" for i in range(CONFIG['num_classes'])]\n",
        "\n",
        "    # Run inference\n",
        "    detections = perform_inference(trained_model, test_image, CONFIG['image_size'])\n",
        "\n",
        "    # Visualize detections\n",
        "    if len(detections) > 0:\n",
        "        result_image = visualize_detections(test_image, detections, class_names, CONFIG['image_size'])\n",
        "\n",
        "        # In a real implementation, you would display or save the image\n",
        "        print(f\"Detected {len(detections)} objects in the test image\")\n",
        "    else:\n",
        "        print(\"No objects detected in the test image\")\n",
        "\n",
        "    print(\"\\nObject Detection Project Completed\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "tNR5Ho3IJzrl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}